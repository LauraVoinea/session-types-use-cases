/**
 * Generated by pabble-mpi v1.2.1
 * Date: Mon Oct 27 12:13:31 2014
 */
#include <math.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <mpi.h>
#include <scribble/pabble.h>

/*** MPI tags ***/
#define Init 0
#define LoopBegin 1
#define LeftToRight 2
#define RightToLeft 3
#define UpToDown 4
#define DownToUp 5
#define LoopEnd 6
#define Finish 7
#define Worker_RANK(x,y) (0+((x)-(1))*((N)-(1))+((y)-(1)))

extern meta_t meta;


int main(int argc, char *argv[])
{
  double ts_overall=0.0, ts_protocol=0.0;
  MPI_Init(&argc, &argv);
  ts_overall = MPI_Wtime();
  meta.comm = MPI_COMM_WORLD;
  MPI_Comm_rank(MPI_COMM_WORLD, &meta.pid);
  MPI_Comm_size(MPI_COMM_WORLD, &meta.nprocs);
  MPI_Group world_grp;
  MPI_Comm_group(MPI_COMM_WORLD, &world_grp);
  /** Declarations (Protocol TwoWayMesh) **/
  int N = ((int) pow((double)meta.nprocs, 1/2));
  MPI_Barrier(MPI_COMM_WORLD); /* Protocol begin */
  int cond0 = 0;
  for (int x=1; x<=N; x++)
     cond0 |= ( Worker_RANK(x,2) <= meta.pid && meta.pid <= Worker_RANK(x,N) );
#pragma pabble type T
  typedef void T;
  MPI_Datatype MPI_T = MPI_BYTE;
  T *bufLeftToRight0_r;
  MPI_Request req0_r; MPI_Status stat0_r;
  int cond1 = 0;
  for (int x=1; x<=N; x++)
     cond1 |= ( Worker_RANK(x,1) <= meta.pid && meta.pid <= Worker_RANK(x,(N-1)) );
  T *bufLeftToRight0_s;
  MPI_Request req0_s; MPI_Status stat0_s;
  int cond2 = 0;
  for (int x=1; x<=N; x++)
     cond2 |= ( Worker_RANK(x,1) <= meta.pid && meta.pid <= Worker_RANK(x,(N-1)) );
  T *bufRightToLeft1_r;
  MPI_Request req1_r; MPI_Status stat1_r;
  int cond3 = 0;
  for (int x=1; x<=N; x++)
     cond3 |= ( Worker_RANK(x,2) <= meta.pid && meta.pid <= Worker_RANK(x,N) );
  T *bufRightToLeft1_s;
  MPI_Request req1_s; MPI_Status stat1_s;
  int cond4 = 0;
  for (int x=2; x<=N; x++)
     cond4 |= ( Worker_RANK(x,1) <= meta.pid && meta.pid <= Worker_RANK(x,N) );
  T *bufUpToDown2_r;
  MPI_Request req2_r; MPI_Status stat2_r;
  int cond5 = 0;
  for (int x=1; x<=(N-1); x++)
     cond5 |= ( Worker_RANK(x,1) <= meta.pid && meta.pid <= Worker_RANK(x,N) );
  T *bufUpToDown2_s;
  MPI_Request req2_s; MPI_Status stat2_s;
  int cond6 = 0;
  for (int x=1; x<=(N-1); x++)
     cond6 |= ( Worker_RANK(x,1) <= meta.pid && meta.pid <= Worker_RANK(x,N) );
  T *bufDownToUp3_r;
  MPI_Request req3_r; MPI_Status stat3_r;
  int cond7 = 0;
  for (int x=2; x<=N; x++)
     cond7 |= ( Worker_RANK(x,1) <= meta.pid && meta.pid <= Worker_RANK(x,N) );
  T *bufDownToUp3_s;
  MPI_Request req3_s; MPI_Status stat3_s;
  ts_protocol=MPI_Wtime();
#pragma pabble Init
#pragma pabble recur Steps
  while (1/*Steps*/) {
#pragma pabble LoopBegin
    if (cond0) {
     bufLeftToRight0_r = calloc(meta.buflen(LeftToRight), sizeof(T));
     MPI_Irecv(bufLeftToRight0_r, meta.buflen(LeftToRight), MPI_T, /*Worker[r][(c-1)]*/meta.pid+(0)*(N-1+1)+((0-1)), LeftToRight, meta.comm, &req0_r);
     MPI_Wait(&req0_r, &stat0_r);
     pabble_recvq_enqueue(LeftToRight, bufLeftToRight0_r);
#pragma pabble LeftToRight
    }
    if (cond1) {
#pragma pabble LeftToRight
     bufLeftToRight0_s = pabble_sendq_dequeue();
     MPI_Isend(bufLeftToRight0_s, meta.buflen(LeftToRight), MPI_T, /*Worker[r][(c+1)]*/meta.pid+(0)*(N-1+1)+((0+1)), LeftToRight, meta.comm, &req0_s);
     MPI_Wait(&req0_s, &stat0_s);
     free(bufLeftToRight0_s);
    }
    if (cond2) {
     bufRightToLeft1_r = calloc(meta.buflen(RightToLeft), sizeof(T));
     MPI_Irecv(bufRightToLeft1_r, meta.buflen(RightToLeft), MPI_T, /*Worker[r][(c+1)]*/meta.pid+(0)*(N-1+1)+((0+1)), RightToLeft, meta.comm, &req1_r);
     MPI_Wait(&req1_r, &stat1_r);
     pabble_recvq_enqueue(RightToLeft, bufRightToLeft1_r);
#pragma pabble RightToLeft
    }
    if (cond3) {
#pragma pabble RightToLeft
     bufRightToLeft1_s = pabble_sendq_dequeue();
     MPI_Isend(bufRightToLeft1_s, meta.buflen(RightToLeft), MPI_T, /*Worker[r][(c-1)]*/meta.pid+(0)*(N-1+1)+((0-1)), RightToLeft, meta.comm, &req1_s);
     MPI_Wait(&req1_s, &stat1_s);
     free(bufRightToLeft1_s);
    }
    if (cond4) {
     bufUpToDown2_r = calloc(meta.buflen(UpToDown), sizeof(T));
     MPI_Irecv(bufUpToDown2_r, meta.buflen(UpToDown), MPI_T, /*Worker[(r-1)][c]*/meta.pid+((0-1))*(N-1+1)+(0), UpToDown, meta.comm, &req2_r);
     MPI_Wait(&req2_r, &stat2_r);
     pabble_recvq_enqueue(UpToDown, bufUpToDown2_r);
#pragma pabble UpToDown
    }
    if (cond5) {
#pragma pabble UpToDown
     bufUpToDown2_s = pabble_sendq_dequeue();
     MPI_Isend(bufUpToDown2_s, meta.buflen(UpToDown), MPI_T, /*Worker[(r+1)][c]*/meta.pid+((0+1))*(N-1+1)+(0), UpToDown, meta.comm, &req2_s);
     MPI_Wait(&req2_s, &stat2_s);
     free(bufUpToDown2_s);
    }
    if (cond6) {
     bufDownToUp3_r = calloc(meta.buflen(DownToUp), sizeof(T));
     MPI_Irecv(bufDownToUp3_r, meta.buflen(DownToUp), MPI_T, /*Worker[(r+1)][c]*/meta.pid+((0+1))*(N-1+1)+(0), DownToUp, meta.comm, &req3_r);
     MPI_Wait(&req3_r, &stat3_r);
     pabble_recvq_enqueue(DownToUp, bufDownToUp3_r);
#pragma pabble DownToUp
    }
    if (cond7) {
#pragma pabble DownToUp
     bufDownToUp3_s = pabble_sendq_dequeue();
     MPI_Isend(bufDownToUp3_s, meta.buflen(DownToUp), MPI_T, /*Worker[(r-1)][c]*/meta.pid+((0-1))*(N-1+1)+(0), DownToUp, meta.comm, &req3_s);
     MPI_Wait(&req3_s, &stat3_s);
     free(bufDownToUp3_s);
    }
#pragma pabble LoopEnd
    continue;
   break;
  }
#pragma pabble Finish
  MPI_Barrier(MPI_COMM_WORLD); /* Protocol end */
  ts_protocol=MPI_Wtime()-ts_protocol;
  ts_overall=MPI_Wtime()-ts_overall;
  MPI_Finalize();
  if (meta.pid==0) fprintf(stderr, "Protocol=%fs Overall=%f\n", ts_protocol, ts_overall);
  return EXIT_SUCCESS;
}
